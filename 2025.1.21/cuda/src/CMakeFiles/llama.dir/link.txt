/home/co/miniconda3/bin/x86_64-conda-linux-gnu-c++ -fPIC -fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/co/miniconda3/include  -I/home/co/miniconda3/targets/x86_64-linux/include  -L/home/co/miniconda3/targets/x86_64-linux/lib -L/home/co/miniconda3/targets/x86_64-linux/lib/stubs -O3 -DNDEBUG -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/co/miniconda3/lib -Wl,-rpath-link,/home/co/miniconda3/lib -L/home/co/miniconda3/lib  -L/home/co/miniconda3/targets/x86_64-linux/lib -L/home/co/miniconda3/targets/x86_64-linux/lib/stubs -shared -Wl,-soname,libllama.so -o libllama.so CMakeFiles/llama.dir/llama.cpp.o "CMakeFiles/llama.dir/llama-adapter.cpp.o" "CMakeFiles/llama.dir/llama-arch.cpp.o" "CMakeFiles/llama.dir/llama-batch.cpp.o" "CMakeFiles/llama.dir/llama-chat.cpp.o" "CMakeFiles/llama.dir/llama-context.cpp.o" "CMakeFiles/llama.dir/llama-grammar.cpp.o" "CMakeFiles/llama.dir/llama-hparams.cpp.o" "CMakeFiles/llama.dir/llama-impl.cpp.o" "CMakeFiles/llama.dir/llama-kv-cache.cpp.o" "CMakeFiles/llama.dir/llama-mmap.cpp.o" "CMakeFiles/llama.dir/llama-model-loader.cpp.o" "CMakeFiles/llama.dir/llama-model.cpp.o" "CMakeFiles/llama.dir/llama-quant.cpp.o" "CMakeFiles/llama.dir/llama-sampling.cpp.o" "CMakeFiles/llama.dir/llama-vocab.cpp.o" CMakeFiles/llama.dir/unicode.cpp.o "CMakeFiles/llama.dir/unicode-data.cpp.o"  -Wl,-rpath,/home/co/llama.cpp/build/ggml/src:/home/co/llama.cpp/build/ggml/src/ggml-cuda: ../ggml/src/libggml.so ../ggml/src/libggml-cpu.so ../ggml/src/ggml-cuda/libggml-cuda.so ../ggml/src/libggml-base.so /home/co/miniconda3/targets/x86_64-linux/lib/stubs/libcuda.so
